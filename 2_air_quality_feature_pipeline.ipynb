{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4447764c-218b-441a-ab97-4df4062960d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local environment\n",
      "Added the following directory to the PYTHONPATH: /Users/kcah/Documents/code-repo/air-quality-prediction\n",
      "HopsworksSettings initialized!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def is_google_colab() -> bool:\n",
    "    if \"google.colab\" in str(get_ipython()):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    !git clone https://github.com/featurestorebook/mlfs-book.git\n",
    "    %cd mlfs-book\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "if is_google_colab():\n",
    "    clone_repository()\n",
    "    install_dependencies()\n",
    "    root_dir = str(Path().absolute())\n",
    "    print(\"Google Colab environment\")\n",
    "else:\n",
    "    root_dir = Path().absolute()\n",
    "    # Strip ~/notebooks/ccfraud from PYTHON_PATH if notebook started in one of these subdirectories\n",
    "    if root_dir.parts[-1:] == ('airquality',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    if root_dir.parts[-1:] == ('notebooks',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    root_dir = str(root_dir) \n",
    "    print(\"Local environment\")\n",
    "\n",
    "# Add the root directory to the `PYTHONPATH` to use the `recsys` Python module from the notebook.\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "print(f\"Added the following directory to the PYTHONPATH: {root_dir}\")\n",
    "    \n",
    "# Set the environment variables from the file <root_dir>/.env\n",
    "from mlfs import config\n",
    "settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e46aad",
   "metadata": {},
   "source": [
    "<span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 02: Daily Feature Pipeline for Air Quality (aqicn.org) and weather (openmeteo)</span>\n",
    "\n",
    "## üóíÔ∏è This notebook is divided into the following sections:\n",
    "1. Download and Parse Data\n",
    "2. Feature Group Insertion\n",
    "\n",
    "\n",
    "__This notebook should be scheduled to run daily__\n",
    "\n",
    "In the book, we use a GitHub Action stored here:\n",
    "[.github/workflows/air-quality-daily.yml](https://github.com/featurestorebook/mlfs-book/blob/main/.github/workflows/air-quality-daily.yml)\n",
    "\n",
    "However, you are free to use any Python Orchestration tool to schedule this program to run daily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe638c6",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7de2e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "from mlfs.airquality import util\n",
    "from mlfs import config\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6081d1",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç Get the Sensor URL, Country, City, Street names from Hopsworks </span>\n",
    "\n",
    "__Update the values in the cell below.__\n",
    "\n",
    "__These should be the same values as in notebook 1 - the feature backfill notebook__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b70cd57d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 21:45:17,510 INFO: Initializing external client\n",
      "2025-11-17 21:45:17,510 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 21:45:19,072 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1279136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"country\": \"finland\", \"city\": \"helsinki\", \"street\": \"kluuvi\", \"aqicn_url\": \"https://api.waqi.info/feed/@5717\", \"latitude\": \"60.1733244\", \"longitude\": \"24.9410248\"}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store() \n",
    "secrets = hopsworks.get_secrets_api()\n",
    "\n",
    "# This line will fail if you have not registered the AQICN_API_KEY as a secret in Hopsworks\n",
    "AQICN_API_KEY = secrets.get_secret(\"AQICN_API_KEY\").value\n",
    "location_str = secrets.get_secret(\"SENSOR_LOCATION_JSON\").value\n",
    "location = json.loads(location_str)\n",
    "\n",
    "country=location['country']\n",
    "city=location['city']\n",
    "street=location['street']\n",
    "aqicn_url=location['aqicn_url']\n",
    "latitude=location['latitude']\n",
    "longitude=location['longitude']\n",
    "\n",
    "today = datetime.datetime.today().replace(hour=0, minute=0, second=0, microsecond=0) \n",
    "\n",
    "location_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c933b084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2caf9289",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> üîÆ Get references to the Feature Groups </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66f5d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature groups\n",
    "air_quality_fg = fs.get_feature_group(\n",
    "    name='air_quality_lag',\n",
    "    version=1,\n",
    ")\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name='weather_extended',\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b6ce8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7ffa41",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üå´ Retrieve Today's Air Quality data (PM2.5) from the AQI API</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f681af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm25</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>street</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>finland</td>\n",
       "      <td>helsinki</td>\n",
       "      <td>kluuvi</td>\n",
       "      <td>2025-11-17</td>\n",
       "      <td>https://api.waqi.info/feed/@5717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pm25  country      city  street       date  \\\n",
       "0  18.0  finland  helsinki  kluuvi 2025-11-17   \n",
       "\n",
       "                                url  \n",
       "0  https://api.waqi.info/feed/@5717  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "aq_today_df = util.get_pm25(aqicn_url, country, city, street, today, AQICN_API_KEY)\n",
    "aq_today_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9e24eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count  Dtype         \n",
      "---  ------   --------------  -----         \n",
      " 0   pm25     1 non-null      float32       \n",
      " 1   country  1 non-null      object        \n",
      " 2   city     1 non-null      object        \n",
      " 3   street   1 non-null      object        \n",
      " 4   date     1 non-null      datetime64[us]\n",
      " 5   url      1 non-null      object        \n",
      "dtypes: datetime64[us](1), float32(1), object(4)\n",
      "memory usage: 176.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "aq_today_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c77eb59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "# import pandas as pd\n",
    "\n",
    "# # Convert string dates to date objects\n",
    "# date_start = datetime.date(2025, 11, 12)\n",
    "# date_end = datetime.date(2025, 11, 16)\n",
    "\n",
    "# # Read data for both dates\n",
    "# historical_data = air_quality_fg.filter(\n",
    "#     (air_quality_fg.country == country) &\n",
    "#     (air_quality_fg.city == city) &\n",
    "#     (air_quality_fg.street == street) &\n",
    "#     (air_quality_fg.date >= date_start) &\n",
    "#     (air_quality_fg.date <= date_end)\n",
    "# ).read()\n",
    "\n",
    "# # Sort by date\n",
    "# historical_data = historical_data.sort_values('date')\n",
    "# historical_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49023549",
   "metadata": {},
   "source": [
    "## Add Lagged Air Quality Features\n",
    "\n",
    "We will retrieve the previous 1, 2, and 3 days of air quality data from the feature store and add them as lagged features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b75d5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.66s) \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm25</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>street</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "      <th>pm25_lag_1d</th>\n",
       "      <th>pm25_lag_2d</th>\n",
       "      <th>pm25_lag_3d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>finland</td>\n",
       "      <td>helsinki</td>\n",
       "      <td>kluuvi</td>\n",
       "      <td>2025-11-17</td>\n",
       "      <td>https://api.waqi.info/feed/@5717</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pm25  country      city  street       date  \\\n",
       "0  18.0  finland  helsinki  kluuvi 2025-11-17   \n",
       "\n",
       "                                url  pm25_lag_1d  pm25_lag_2d  pm25_lag_3d  \n",
       "0  https://api.waqi.info/feed/@5717          9.0         13.0         13.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve previous days' air quality data to create lagged features\n",
    "from datetime import timedelta\n",
    "from datetime import timezone\n",
    "\n",
    "# Get dates for 1, 2, and 3 days ago, set to midnight and normalize to UTC\n",
    "today = pd.Timestamp.now(tz='UTC')\n",
    "date_1d_ago = (today - timedelta(days=1)).astimezone(timezone.utc).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "date_2d_ago = (today - timedelta(days=2)).astimezone(timezone.utc).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "date_3d_ago = (today - timedelta(days=3)).astimezone(timezone.utc).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "date_4d_ago = (today - timedelta(days=4)).astimezone(timezone.utc).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "# Initialize lagged features as None\n",
    "aq_today_df['pm25_lag_1d'] = None\n",
    "aq_today_df['pm25_lag_2d'] = None\n",
    "aq_today_df['pm25_lag_3d'] = None\n",
    "\n",
    "# Try to retrieve previous days' data from the feature store\n",
    "try:\n",
    "    # Query for previous days' pm25 values\n",
    "    historical_data = air_quality_fg.filter(\n",
    "        (air_quality_fg.country == country) &\n",
    "        (air_quality_fg.city == city) &\n",
    "        (air_quality_fg.street == street) &\n",
    "        (air_quality_fg.date >= date_4d_ago) &\n",
    "        (air_quality_fg.date < today)\n",
    "    ).read()\n",
    "    \n",
    "    # Select only the columns we need\n",
    "    historical_data = historical_data[['date', 'pm25']]\n",
    "    \n",
    "    # Sort by date\n",
    "    historical_data = historical_data.sort_values('date')\n",
    "    \n",
    "    # Normalize historical_data dates to UTC to match comparison timestamps\n",
    "    # This handles the Etc/UTC vs UTC timezone difference\n",
    "    if historical_data['date'].dt.tz is not None:\n",
    "        historical_data['date'] = historical_data['date'].dt.tz_convert('UTC')\n",
    "    \n",
    "    # Get the pm25 values for 1, 2, and 3 days ago\n",
    "    for idx, row in aq_today_df.iterrows():\n",
    "        # Convert dates to pandas Timestamps and normalize to UTC for comparison\n",
    "        ts_1d_ago = pd.Timestamp(date_1d_ago).tz_convert('UTC')\n",
    "        ts_2d_ago = pd.Timestamp(date_2d_ago).tz_convert('UTC')\n",
    "        ts_3d_ago = pd.Timestamp(date_3d_ago).tz_convert('UTC')\n",
    "        \n",
    "        # Get pm25 for 1 day ago\n",
    "        lag_1d = historical_data[historical_data['date'] == ts_1d_ago]\n",
    "        if not lag_1d.empty:\n",
    "            aq_today_df.at[idx, 'pm25_lag_1d'] = lag_1d['pm25'].iloc[0]\n",
    "        \n",
    "        # Get pm25 for 2 days ago\n",
    "        lag_2d = historical_data[historical_data['date'] == ts_2d_ago]\n",
    "        if not lag_2d.empty:\n",
    "            aq_today_df.at[idx, 'pm25_lag_2d'] = lag_2d['pm25'].iloc[0]\n",
    "        \n",
    "        lag_3d = historical_data[historical_data['date'] == date_3d_ago]\n",
    "        if not lag_3d.empty:\n",
    "            aq_today_df.at[idx, 'pm25_lag_3d'] = lag_3d['pm25'].iloc[0]\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Could not retrieve lagged features: {e}\")\n",
    "    print(\"Lagged features will be set to None for this day\")\n",
    "    raise e\n",
    "\n",
    "# Convert lagged features to float32, handling None values\n",
    "aq_today_df['pm25_lag_1d'] = pd.to_numeric(aq_today_df['pm25_lag_1d'], errors='coerce').astype('float32')\n",
    "aq_today_df['pm25_lag_2d'] = pd.to_numeric(aq_today_df['pm25_lag_2d'], errors='coerce').astype('float32')\n",
    "aq_today_df['pm25_lag_3d'] = pd.to_numeric(aq_today_df['pm25_lag_3d'], errors='coerce').astype('float32')\n",
    "\n",
    "aq_today_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af845ab6",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üå¶ Get Weather Forecast data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ecb3e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "get_hourly_weather_forecast() missing 2 required positional arguments: 'start_date' and 'end_date'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m hourly_df = \u001b[43mutil\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_hourly_weather_forecast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcity\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatitude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlongitude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m hourly_df = hourly_df.set_index(\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# We will only make 1 daily prediction, so we will replace the hourly forecasts with a single daily forecast\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# We only want the daily weather data, so only get weather at 12:00\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: get_hourly_weather_forecast() missing 2 required positional arguments: 'start_date' and 'end_date'"
     ]
    }
   ],
   "source": [
    "hourly_df = util.get_hourly_weather_forecast(city, latitude, longitude, start_date=)\n",
    "hourly_df = hourly_df.set_index('date')\n",
    "\n",
    "# We will only make 1 daily prediction, so we will replace the hourly forecasts with a single daily forecast\n",
    "# We only want the daily weather data, so only get weather at 12:00\n",
    "daily_df = hourly_df.between_time('11:59', '12:01')\n",
    "daily_df = daily_df.reset_index()\n",
    "daily_df['date'] = pd.to_datetime(daily_df['date']).dt.date\n",
    "daily_df['date'] = pd.to_datetime(daily_df['date'])\n",
    "daily_df['city'] = city\n",
    "daily_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3793778c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>rain_sum</th>\n",
       "      <th>wind_speed_10m_max</th>\n",
       "      <th>wind_direction_10m_dominant</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-11-17 00:00:00</th>\n",
       "      <td>2.40</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8.891343</td>\n",
       "      <td>238.240555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-17 01:00:00</th>\n",
       "      <td>1.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.618519</td>\n",
       "      <td>247.619812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-17 02:00:00</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.320000</td>\n",
       "      <td>270.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-17 03:00:00</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>306.869965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-17 04:00:00</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.510787</td>\n",
       "      <td>331.389618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-23 19:00:00</th>\n",
       "      <td>2.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.299694</td>\n",
       "      <td>133.210114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-23 20:00:00</th>\n",
       "      <td>2.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.884428</td>\n",
       "      <td>130.100845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-23 21:00:00</th>\n",
       "      <td>2.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.513195</td>\n",
       "      <td>127.504219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-23 22:00:00</th>\n",
       "      <td>3.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.883102</td>\n",
       "      <td>125.882233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-23 23:00:00</th>\n",
       "      <td>3.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.267679</td>\n",
       "      <td>124.460876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>168 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     temperature_2m_mean  precipitation_sum  rain_sum  \\\n",
       "date                                                                    \n",
       "2025-11-17 00:00:00                 2.40                0.2       0.2   \n",
       "2025-11-17 01:00:00                 1.80                0.0       0.0   \n",
       "2025-11-17 02:00:00                 0.95                0.0       0.0   \n",
       "2025-11-17 03:00:00                 0.40                0.0       0.0   \n",
       "2025-11-17 04:00:00                 0.35                0.0       0.0   \n",
       "...                                  ...                ...       ...   \n",
       "2025-11-23 19:00:00                 2.25                0.0       0.0   \n",
       "2025-11-23 20:00:00                 2.55                0.0       0.0   \n",
       "2025-11-23 21:00:00                 2.80                0.0       0.0   \n",
       "2025-11-23 22:00:00                 3.05                0.0       0.0   \n",
       "2025-11-23 23:00:00                 3.25                0.0       0.0   \n",
       "\n",
       "                     wind_speed_10m_max  wind_direction_10m_dominant  \n",
       "date                                                                  \n",
       "2025-11-17 00:00:00            8.891343                   238.240555  \n",
       "2025-11-17 01:00:00            6.618519                   247.619812  \n",
       "2025-11-17 02:00:00            4.320000                   270.000000  \n",
       "2025-11-17 03:00:00            3.600000                   306.869965  \n",
       "2025-11-17 04:00:00            4.510787                   331.389618  \n",
       "...                                 ...                          ...  \n",
       "2025-11-23 19:00:00           16.299694                   133.210114  \n",
       "2025-11-23 20:00:00           17.884428                   130.100845  \n",
       "2025-11-23 21:00:00           19.513195                   127.504219  \n",
       "2025-11-23 22:00:00           20.883102                   125.882233  \n",
       "2025-11-23 23:00:00           22.267679                   124.460876  \n",
       "\n",
       "[168 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c563109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7 entries, 0 to 6\n",
      "Data columns (total 7 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   date                         7 non-null      datetime64[ns]\n",
      " 1   temperature_2m_mean          7 non-null      float32       \n",
      " 2   precipitation_sum            7 non-null      float32       \n",
      " 3   rain_sum                     7 non-null      float32       \n",
      " 4   wind_speed_10m_max           7 non-null      float32       \n",
      " 5   wind_direction_10m_dominant  7 non-null      float32       \n",
      " 6   city                         7 non-null      object        \n",
      "dtypes: datetime64[ns](1), float32(5), object(1)\n",
      "memory usage: 384.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "daily_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1f5008",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:#ff5f27;\">‚¨ÜÔ∏è Uploading new data to the Feature Store</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9de5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 19:29:43,994 INFO: \t1 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1279136/fs/1265746/fg/1721860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 1/1 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: air_quality_lag_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1279136/jobs/named/air_quality_lag_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('air_quality_lag_1_offline_fg_materialization', 'SPARK'),\n",
       " {\n",
       "   \"success\": true,\n",
       "   \"results\": [\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"pm25\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 500.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 762063\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 20.0,\n",
       "         \"element_count\": 1,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2025-11-17T06:29:43.000994Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     }\n",
       "   ],\n",
       "   \"evaluation_parameters\": {},\n",
       "   \"statistics\": {\n",
       "     \"evaluated_expectations\": 1,\n",
       "     \"successful_expectations\": 1,\n",
       "     \"unsuccessful_expectations\": 0,\n",
       "     \"success_percent\": 100.0\n",
       "   },\n",
       "   \"meta\": {\n",
       "     \"great_expectations_version\": \"0.18.12\",\n",
       "     \"expectation_suite_name\": \"aq_expectation_suite\",\n",
       "     \"run_id\": {\n",
       "       \"run_name\": null,\n",
       "       \"run_time\": \"2025-11-17T19:29:43.994488+01:00\"\n",
       "     },\n",
       "     \"batch_kwargs\": {\n",
       "       \"ge_batch_id\": \"63540a54-c3e3-11f0-9764-b3559b7df3d4\"\n",
       "     },\n",
       "     \"batch_markers\": {},\n",
       "     \"batch_parameters\": {},\n",
       "     \"validation_time\": \"20251117T182943.994352Z\",\n",
       "     \"expectation_suite_meta\": {\n",
       "       \"great_expectations_version\": \"0.18.12\"\n",
       "     }\n",
       "   }\n",
       " })"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert new data\n",
    "air_quality_fg.insert(aq_today_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d491b0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 19:29:58,108 INFO: \t2 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1279136/fs/1265746/fg/1718851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 7/7 | Elapsed Time: 00:00 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: weather_extended_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1279136/jobs/named/weather_extended_1_offline_fg_materialization/executions\n",
      "2025-11-17 19:30:15,275 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-11-17 19:30:18,453 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-11-17 19:32:13,179 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-11-17 19:32:13,346 INFO: Waiting for log aggregation to finish.\n",
      "2025-11-17 19:32:21,950 INFO: Execution finished successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('weather_extended_1_offline_fg_materialization', 'SPARK'),\n",
       " {\n",
       "   \"success\": true,\n",
       "   \"results\": [\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"precipitation_sum\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 1000.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 758981\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 0.0,\n",
       "         \"element_count\": 7,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2025-11-17T06:29:58.000108Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     },\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"wind_speed_10m_max\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 1000.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 758980\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 5.991593837738037,\n",
       "         \"element_count\": 7,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2025-11-17T06:29:58.000108Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     }\n",
       "   ],\n",
       "   \"evaluation_parameters\": {},\n",
       "   \"statistics\": {\n",
       "     \"evaluated_expectations\": 2,\n",
       "     \"successful_expectations\": 2,\n",
       "     \"unsuccessful_expectations\": 0,\n",
       "     \"success_percent\": 100.0\n",
       "   },\n",
       "   \"meta\": {\n",
       "     \"great_expectations_version\": \"0.18.12\",\n",
       "     \"expectation_suite_name\": \"weather_expectation_suite\",\n",
       "     \"run_id\": {\n",
       "       \"run_name\": null,\n",
       "       \"run_time\": \"2025-11-17T19:29:58.108897+01:00\"\n",
       "     },\n",
       "     \"batch_kwargs\": {\n",
       "       \"ge_batch_id\": \"6bbde6b0-c3e3-11f0-9764-b3559b7df3d4\"\n",
       "     },\n",
       "     \"batch_markers\": {},\n",
       "     \"batch_parameters\": {},\n",
       "     \"validation_time\": \"20251117T182958.108844Z\",\n",
       "     \"expectation_suite_meta\": {\n",
       "       \"great_expectations_version\": \"0.18.12\"\n",
       "     }\n",
       "   }\n",
       " })"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert new data\n",
    "weather_fg.insert(daily_df, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e9e2d",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Next:** Part 03: Training Pipeline\n",
    " </span> \n",
    "\n",
    "In the following notebook you will read from a feature group and create training dataset within the feature store\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
