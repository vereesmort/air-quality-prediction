{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4447764c-218b-441a-ab97-4df4062960d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local environment\n",
      "Added the following directory to the PYTHONPATH: /Users/kcah/Documents/code-repo/air-quality-prediction\n",
      "HopsworksSettings initialized!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def is_google_colab() -> bool:\n",
    "    if \"google.colab\" in str(get_ipython()):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def clone_repository() -> None:\n",
    "    !git clone https://github.com/featurestorebook/mlfs-book.git\n",
    "    %cd mlfs-book\n",
    "\n",
    "def install_dependencies() -> None:\n",
    "    !pip install --upgrade uv\n",
    "    !uv pip install --all-extras --system --requirement pyproject.toml\n",
    "\n",
    "if is_google_colab():\n",
    "    clone_repository()\n",
    "    install_dependencies()\n",
    "    root_dir = str(Path().absolute())\n",
    "    print(\"Google Colab environment\")\n",
    "else:\n",
    "    root_dir = Path().absolute()\n",
    "    # Strip ~/notebooks/ccfraud from PYTHON_PATH if notebook started in one of these subdirectories\n",
    "    if root_dir.parts[-1:] == ('airquality',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    if root_dir.parts[-1:] == ('notebooks',):\n",
    "        root_dir = Path(*root_dir.parts[:-1])\n",
    "    root_dir = str(root_dir) \n",
    "    print(\"Local environment\")\n",
    "\n",
    "# Add the root directory to the `PYTHONPATH` to use the `recsys` Python module from the notebook.\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "print(f\"Added the following directory to the PYTHONPATH: {root_dir}\")\n",
    "    \n",
    "# Set the environment variables from the file <root_dir>/.env\n",
    "from mlfs import config\n",
    "settings = config.HopsworksSettings(_env_file=f\"{root_dir}/.env\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e46aad",
   "metadata": {},
   "source": [
    "<span style=\"font-width:bold; font-size: 3rem; color:#333;\">- Part 02: Daily Feature Pipeline for Air Quality (aqicn.org) and weather (openmeteo)</span>\n",
    "\n",
    "## üóíÔ∏è This notebook is divided into the following sections:\n",
    "1. Download and Parse Data\n",
    "2. Feature Group Insertion\n",
    "\n",
    "\n",
    "__This notebook should be scheduled to run daily__\n",
    "\n",
    "In the book, we use a GitHub Action stored here:\n",
    "[.github/workflows/air-quality-daily.yml](https://github.com/featurestorebook/mlfs-book/blob/main/.github/workflows/air-quality-daily.yml)\n",
    "\n",
    "However, you are free to use any Python Orchestration tool to schedule this program to run daily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe638c6",
   "metadata": {},
   "source": [
    "### <span style='color:#ff5f27'> üìù Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7de2e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import hopsworks\n",
    "from mlfs.airquality import util\n",
    "from mlfs import config\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6081d1",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üåç Get the Sensor URL, Country, City, Street names from Hopsworks </span>\n",
    "\n",
    "__Update the values in the cell below.__\n",
    "\n",
    "__These should be the same values as in notebook 1 - the feature backfill notebook__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b70cd57d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 21:45:17,510 INFO: Initializing external client\n",
      "2025-11-17 21:45:17,510 INFO: Base URL: https://c.app.hopsworks.ai:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 21:45:19,072 INFO: Python Engine initialized.\n",
      "\n",
      "Logged in to project, explore it here https://c.app.hopsworks.ai:443/p/1279136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"country\": \"finland\", \"city\": \"helsinki\", \"street\": \"kluuvi\", \"aqicn_url\": \"https://api.waqi.info/feed/@5717\", \"latitude\": \"60.1733244\", \"longitude\": \"24.9410248\"}'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = hopsworks.login()\n",
    "fs = project.get_feature_store() \n",
    "secrets = hopsworks.get_secrets_api()\n",
    "\n",
    "# This line will fail if you have not registered the AQICN_API_KEY as a secret in Hopsworks\n",
    "AQICN_API_KEY = secrets.get_secret(\"AQICN_API_KEY\").value\n",
    "location_str = secrets.get_secret(\"SENSOR_LOCATION_JSON\").value\n",
    "location = json.loads(location_str)\n",
    "\n",
    "country=location['country']\n",
    "city=location['city']\n",
    "street=location['street']\n",
    "aqicn_url=location['aqicn_url']\n",
    "latitude=location['latitude']\n",
    "longitude=location['longitude']\n",
    "\n",
    "today = datetime.datetime.today().replace(hour=0, minute=0, second=0, microsecond=0) \n",
    "\n",
    "location_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c933b084",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2caf9289",
   "metadata": {},
   "source": [
    "### <span style=\"color:#ff5f27;\"> üîÆ Get references to the Feature Groups </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66f5d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve feature groups\n",
    "air_quality_fg = fs.get_feature_group(\n",
    "    name='air_quality_lag',\n",
    "    version=1,\n",
    ")\n",
    "weather_fg = fs.get_feature_group(\n",
    "    name='weather_extended',\n",
    "    version=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10b6ce8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a7ffa41",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üå´ Retrieve Today's Air Quality data (PM2.5) from the AQI API</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f681af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm25</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>street</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>finland</td>\n",
       "      <td>helsinki</td>\n",
       "      <td>kluuvi</td>\n",
       "      <td>2025-11-17</td>\n",
       "      <td>https://api.waqi.info/feed/@5717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pm25  country      city  street       date  \\\n",
       "0  18.0  finland  helsinki  kluuvi 2025-11-17   \n",
       "\n",
       "                                url  \n",
       "0  https://api.waqi.info/feed/@5717  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "aq_today_df = util.get_pm25(aqicn_url, country, city, street, today, AQICN_API_KEY)\n",
    "aq_today_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9e24eda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1 entries, 0 to 0\n",
      "Data columns (total 6 columns):\n",
      " #   Column   Non-Null Count  Dtype         \n",
      "---  ------   --------------  -----         \n",
      " 0   pm25     1 non-null      float32       \n",
      " 1   country  1 non-null      object        \n",
      " 2   city     1 non-null      object        \n",
      " 3   street   1 non-null      object        \n",
      " 4   date     1 non-null      datetime64[us]\n",
      " 5   url      1 non-null      object        \n",
      "dtypes: datetime64[us](1), float32(1), object(4)\n",
      "memory usage: 176.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "aq_today_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c77eb59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datetime\n",
    "# import pandas as pd\n",
    "\n",
    "# # Convert string dates to date objects\n",
    "# date_start = datetime.date(2025, 11, 12)\n",
    "# date_end = datetime.date(2025, 11, 16)\n",
    "\n",
    "# # Read data for both dates\n",
    "# historical_data = air_quality_fg.filter(\n",
    "#     (air_quality_fg.country == country) &\n",
    "#     (air_quality_fg.city == city) &\n",
    "#     (air_quality_fg.street == street) &\n",
    "#     (air_quality_fg.date >= date_start) &\n",
    "#     (air_quality_fg.date <= date_end)\n",
    "# ).read()\n",
    "\n",
    "# # Sort by date\n",
    "# historical_data = historical_data.sort_values('date')\n",
    "# historical_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49023549",
   "metadata": {},
   "source": [
    "## Add Lagged Air Quality Features\n",
    "\n",
    "We will retrieve the previous 1, 2, and 3 days of air quality data from the feature store and add them as lagged features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b75d5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: Reading data from Hopsworks, using Hopsworks Feature Query Service (0.66s) \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pm25</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>street</th>\n",
       "      <th>date</th>\n",
       "      <th>url</th>\n",
       "      <th>pm25_lag_1d</th>\n",
       "      <th>pm25_lag_2d</th>\n",
       "      <th>pm25_lag_3d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18.0</td>\n",
       "      <td>finland</td>\n",
       "      <td>helsinki</td>\n",
       "      <td>kluuvi</td>\n",
       "      <td>2025-11-17</td>\n",
       "      <td>https://api.waqi.info/feed/@5717</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pm25  country      city  street       date  \\\n",
       "0  18.0  finland  helsinki  kluuvi 2025-11-17   \n",
       "\n",
       "                                url  pm25_lag_1d  pm25_lag_2d  pm25_lag_3d  \n",
       "0  https://api.waqi.info/feed/@5717          9.0         13.0         13.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve previous days' air quality data to create lagged features\n",
    "from datetime import timedelta\n",
    "from datetime import timezone\n",
    "\n",
    "# Get dates for 1, 2, and 3 days ago, set to midnight and normalize to UTC\n",
    "today = pd.Timestamp.now(tz='UTC')\n",
    "date_1d_ago = (today - timedelta(days=1)).astimezone(timezone.utc).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "date_2d_ago = (today - timedelta(days=2)).astimezone(timezone.utc).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "date_3d_ago = (today - timedelta(days=3)).astimezone(timezone.utc).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "date_4d_ago = (today - timedelta(days=4)).astimezone(timezone.utc).replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "\n",
    "# Initialize lagged features as None\n",
    "aq_today_df['pm25_lag_1d'] = None\n",
    "aq_today_df['pm25_lag_2d'] = None\n",
    "aq_today_df['pm25_lag_3d'] = None\n",
    "\n",
    "# Try to retrieve previous days' data from the feature store\n",
    "try:\n",
    "    # Query for previous days' pm25 values\n",
    "    historical_data = air_quality_fg.filter(\n",
    "        (air_quality_fg.country == country) &\n",
    "        (air_quality_fg.city == city) &\n",
    "        (air_quality_fg.street == street) &\n",
    "        (air_quality_fg.date >= date_4d_ago) &\n",
    "        (air_quality_fg.date < today)\n",
    "    ).read()\n",
    "    \n",
    "    # Select only the columns we need\n",
    "    historical_data = historical_data[['date', 'pm25']]\n",
    "    \n",
    "    # Sort by date\n",
    "    historical_data = historical_data.sort_values('date')\n",
    "    \n",
    "    # Normalize historical_data dates to UTC to match comparison timestamps\n",
    "    # This handles the Etc/UTC vs UTC timezone difference\n",
    "    if historical_data['date'].dt.tz is not None:\n",
    "        historical_data['date'] = historical_data['date'].dt.tz_convert('UTC')\n",
    "    \n",
    "    # Get the pm25 values for 1, 2, and 3 days ago\n",
    "    for idx, row in aq_today_df.iterrows():\n",
    "        # Convert dates to pandas Timestamps and normalize to UTC for comparison\n",
    "        ts_1d_ago = pd.Timestamp(date_1d_ago).tz_convert('UTC')\n",
    "        ts_2d_ago = pd.Timestamp(date_2d_ago).tz_convert('UTC')\n",
    "        ts_3d_ago = pd.Timestamp(date_3d_ago).tz_convert('UTC')\n",
    "        \n",
    "        # Get pm25 for 1 day ago\n",
    "        lag_1d = historical_data[historical_data['date'] == ts_1d_ago]\n",
    "        if not lag_1d.empty:\n",
    "            aq_today_df.at[idx, 'pm25_lag_1d'] = lag_1d['pm25'].iloc[0]\n",
    "        \n",
    "        # Get pm25 for 2 days ago\n",
    "        lag_2d = historical_data[historical_data['date'] == ts_2d_ago]\n",
    "        if not lag_2d.empty:\n",
    "            aq_today_df.at[idx, 'pm25_lag_2d'] = lag_2d['pm25'].iloc[0]\n",
    "        \n",
    "        lag_3d = historical_data[historical_data['date'] == date_3d_ago]\n",
    "        if not lag_3d.empty:\n",
    "            aq_today_df.at[idx, 'pm25_lag_3d'] = lag_3d['pm25'].iloc[0]\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Could not retrieve lagged features: {e}\")\n",
    "    print(\"Lagged features will be set to None for this day\")\n",
    "    raise e\n",
    "\n",
    "# Convert lagged features to float32, handling None values\n",
    "aq_today_df['pm25_lag_1d'] = pd.to_numeric(aq_today_df['pm25_lag_1d'], errors='coerce').astype('float32')\n",
    "aq_today_df['pm25_lag_2d'] = pd.to_numeric(aq_today_df['pm25_lag_2d'], errors='coerce').astype('float32')\n",
    "aq_today_df['pm25_lag_3d'] = pd.to_numeric(aq_today_df['pm25_lag_3d'], errors='coerce').astype('float32')\n",
    "\n",
    "aq_today_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af845ab6",
   "metadata": {},
   "source": [
    "## <span style='color:#ff5f27'> üå¶ Get Weather Forecast data</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ecb3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coordinates 60.25¬∞N 25.0¬∞E\n",
      "Elevation 2.0 m asl\n",
      "Timezone None None\n",
      "Timezone difference to GMT+0 0 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>wind_speed_10m_max</th>\n",
       "      <th>wind_direction_10m_dominant</th>\n",
       "      <th>rain_sum</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-11-17</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.209263</td>\n",
       "      <td>344.744812</td>\n",
       "      <td>0.00</td>\n",
       "      <td>helsinki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-11-18</td>\n",
       "      <td>-2.10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.269782</td>\n",
       "      <td>333.435028</td>\n",
       "      <td>0.00</td>\n",
       "      <td>helsinki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-11-19</td>\n",
       "      <td>-1.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.903619</td>\n",
       "      <td>59.931511</td>\n",
       "      <td>0.00</td>\n",
       "      <td>helsinki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-11-20</td>\n",
       "      <td>2.70</td>\n",
       "      <td>0.1</td>\n",
       "      <td>20.929596</td>\n",
       "      <td>183.945114</td>\n",
       "      <td>0.10</td>\n",
       "      <td>helsinki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-11-21</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.6</td>\n",
       "      <td>14.561099</td>\n",
       "      <td>351.469299</td>\n",
       "      <td>0.30</td>\n",
       "      <td>helsinki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2025-11-22</td>\n",
       "      <td>3.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.966211</td>\n",
       "      <td>244.359039</td>\n",
       "      <td>0.00</td>\n",
       "      <td>helsinki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2025-11-23</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.069400</td>\n",
       "      <td>197.354111</td>\n",
       "      <td>0.00</td>\n",
       "      <td>helsinki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2025-11-24</td>\n",
       "      <td>2.60</td>\n",
       "      <td>0.5</td>\n",
       "      <td>13.493999</td>\n",
       "      <td>189.210953</td>\n",
       "      <td>0.50</td>\n",
       "      <td>helsinki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2025-11-25</td>\n",
       "      <td>3.55</td>\n",
       "      <td>0.2</td>\n",
       "      <td>6.369050</td>\n",
       "      <td>317.290619</td>\n",
       "      <td>0.20</td>\n",
       "      <td>helsinki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2025-11-26</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.5</td>\n",
       "      <td>17.884428</td>\n",
       "      <td>40.100849</td>\n",
       "      <td>0.25</td>\n",
       "      <td>helsinki</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2025-11-27</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.1</td>\n",
       "      <td>14.973576</td>\n",
       "      <td>9.688724</td>\n",
       "      <td>0.00</td>\n",
       "      <td>helsinki</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  temperature_2m_mean  precipitation_sum  wind_speed_10m_max  \\\n",
       "0  2025-11-17                 0.65                0.0            8.209263   \n",
       "1  2025-11-18                -2.10                0.0           11.269782   \n",
       "2  2025-11-19                -1.65                0.0            7.903619   \n",
       "3  2025-11-20                 2.70                0.1           20.929596   \n",
       "4  2025-11-21                 0.40                0.6           14.561099   \n",
       "5  2025-11-22                 3.50                0.0           19.966211   \n",
       "6  2025-11-23                 5.00                0.0           12.069400   \n",
       "7  2025-11-24                 2.60                0.5           13.493999   \n",
       "8  2025-11-25                 3.55                0.2            6.369050   \n",
       "9  2025-11-26                 0.35                0.5           17.884428   \n",
       "10 2025-11-27                -0.25                0.1           14.973576   \n",
       "\n",
       "    wind_direction_10m_dominant  rain_sum      city  \n",
       "0                    344.744812      0.00  helsinki  \n",
       "1                    333.435028      0.00  helsinki  \n",
       "2                     59.931511      0.00  helsinki  \n",
       "3                    183.945114      0.10  helsinki  \n",
       "4                    351.469299      0.30  helsinki  \n",
       "5                    244.359039      0.00  helsinki  \n",
       "6                    197.354111      0.00  helsinki  \n",
       "7                    189.210953      0.50  helsinki  \n",
       "8                    317.290619      0.20  helsinki  \n",
       "9                     40.100849      0.25  helsinki  \n",
       "10                     9.688724      0.00  helsinki  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_date = pd.Timestamp.today().normalize()\n",
    "end_date = start_date + pd.Timedelta(days=10)\n",
    "# Convert dates to 'YYYY-MM-DD' format strings\n",
    "start_date = start_date.strftime('%Y-%m-%d')\n",
    "end_date = end_date.strftime('%Y-%m-%d')\n",
    "hourly_df = util.get_hourly_weather_forecast(city, latitude, longitude, start_date, end_date)\n",
    "hourly_df = hourly_df.set_index('date')\n",
    "\n",
    "# We will only make 1 daily prediction, so we will replace the hourly forecasts with a single daily forecast\n",
    "# We only want the daily weather data, so only get weather at 12:00\n",
    "daily_df = hourly_df.between_time('11:59', '12:01')\n",
    "daily_df = daily_df.reset_index()\n",
    "daily_df['date'] = pd.to_datetime(daily_df['date']).dt.date\n",
    "daily_df['date'] = pd.to_datetime(daily_df['date'])\n",
    "daily_df['city'] = city\n",
    "daily_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3793778c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temperature_2m_mean</th>\n",
       "      <th>precipitation_sum</th>\n",
       "      <th>wind_speed_10m_max</th>\n",
       "      <th>wind_direction_10m_dominant</th>\n",
       "      <th>rain_sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-11-17 00:00:00</th>\n",
       "      <td>2.40</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8.891343</td>\n",
       "      <td>238.240555</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-17 01:00:00</th>\n",
       "      <td>1.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.618519</td>\n",
       "      <td>247.619812</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-17 02:00:00</th>\n",
       "      <td>0.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.320000</td>\n",
       "      <td>270.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-17 03:00:00</th>\n",
       "      <td>0.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.600000</td>\n",
       "      <td>306.869965</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-17 04:00:00</th>\n",
       "      <td>0.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.510787</td>\n",
       "      <td>331.389618</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-27 19:00:00</th>\n",
       "      <td>-0.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.620809</td>\n",
       "      <td>16.189287</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-27 20:00:00</th>\n",
       "      <td>-0.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.587917</td>\n",
       "      <td>17.818983</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-27 21:00:00</th>\n",
       "      <td>-0.70</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.904906</td>\n",
       "      <td>19.093594</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-27 22:00:00</th>\n",
       "      <td>-0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.360001</td>\n",
       "      <td>22.619909</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-11-27 23:00:00</th>\n",
       "      <td>-0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.699793</td>\n",
       "      <td>24.443953</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>264 rows √ó 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     temperature_2m_mean  precipitation_sum  \\\n",
       "date                                                          \n",
       "2025-11-17 00:00:00                 2.40                0.2   \n",
       "2025-11-17 01:00:00                 1.80                0.0   \n",
       "2025-11-17 02:00:00                 0.95                0.0   \n",
       "2025-11-17 03:00:00                 0.40                0.0   \n",
       "2025-11-17 04:00:00                 0.35                0.0   \n",
       "...                                  ...                ...   \n",
       "2025-11-27 19:00:00                -0.65                0.0   \n",
       "2025-11-27 20:00:00                -0.70                0.0   \n",
       "2025-11-27 21:00:00                -0.70                0.0   \n",
       "2025-11-27 22:00:00                -0.75                0.0   \n",
       "2025-11-27 23:00:00                -0.80                0.0   \n",
       "\n",
       "                     wind_speed_10m_max  wind_direction_10m_dominant  rain_sum  \n",
       "date                                                                            \n",
       "2025-11-17 00:00:00            8.891343                   238.240555       0.2  \n",
       "2025-11-17 01:00:00            6.618519                   247.619812       0.0  \n",
       "2025-11-17 02:00:00            4.320000                   270.000000       0.0  \n",
       "2025-11-17 03:00:00            3.600000                   306.869965       0.0  \n",
       "2025-11-17 04:00:00            4.510787                   331.389618       0.0  \n",
       "...                                 ...                          ...       ...  \n",
       "2025-11-27 19:00:00           11.620809                    16.189287       0.0  \n",
       "2025-11-27 20:00:00           10.587917                    17.818983       0.0  \n",
       "2025-11-27 21:00:00            9.904906                    19.093594       0.0  \n",
       "2025-11-27 22:00:00            9.360001                    22.619909       0.0  \n",
       "2025-11-27 23:00:00            8.699793                    24.443953       0.0  \n",
       "\n",
       "[264 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hourly_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c563109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11 entries, 0 to 10\n",
      "Data columns (total 7 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   date                         11 non-null     datetime64[ns]\n",
      " 1   temperature_2m_mean          11 non-null     float32       \n",
      " 2   precipitation_sum            11 non-null     float32       \n",
      " 3   wind_speed_10m_max           11 non-null     float32       \n",
      " 4   wind_direction_10m_dominant  11 non-null     float32       \n",
      " 5   rain_sum                     11 non-null     float32       \n",
      " 6   city                         11 non-null     object        \n",
      "dtypes: datetime64[ns](1), float32(5), object(1)\n",
      "memory usage: 528.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "daily_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1f5008",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:#ff5f27;\">‚¨ÜÔ∏è Uploading new data to the Feature Store</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a9de5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 21:52:22,322 INFO: \t1 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1279136/fs/1265746/fg/1721860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 1/1 | Elapsed Time: 00:01 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: air_quality_lag_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1279136/jobs/named/air_quality_lag_1_offline_fg_materialization/executions\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('air_quality_lag_1_offline_fg_materialization', 'SPARK'),\n",
       " {\n",
       "   \"success\": true,\n",
       "   \"results\": [\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"pm25\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 500.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 762063\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 18.0,\n",
       "         \"element_count\": 1,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2025-11-17T08:52:22.000322Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     }\n",
       "   ],\n",
       "   \"evaluation_parameters\": {},\n",
       "   \"statistics\": {\n",
       "     \"evaluated_expectations\": 1,\n",
       "     \"successful_expectations\": 1,\n",
       "     \"unsuccessful_expectations\": 0,\n",
       "     \"success_percent\": 100.0\n",
       "   },\n",
       "   \"meta\": {\n",
       "     \"great_expectations_version\": \"0.18.12\",\n",
       "     \"expectation_suite_name\": \"aq_expectation_suite\",\n",
       "     \"run_id\": {\n",
       "       \"run_name\": null,\n",
       "       \"run_time\": \"2025-11-17T21:52:22.322446+01:00\"\n",
       "     },\n",
       "     \"batch_kwargs\": {\n",
       "       \"ge_batch_id\": \"507d5d90-c3f7-11f0-8867-43d604ba8dc7\"\n",
       "     },\n",
       "     \"batch_markers\": {},\n",
       "     \"batch_parameters\": {},\n",
       "     \"validation_time\": \"20251117T205222.322365Z\",\n",
       "     \"expectation_suite_meta\": {\n",
       "       \"great_expectations_version\": \"0.18.12\"\n",
       "     }\n",
       "   }\n",
       " })"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert new data\n",
    "air_quality_fg.insert(aq_today_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d491b0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-17 21:52:38,678 INFO: \t2 expectation(s) included in expectation_suite.\n",
      "Validation succeeded.\n",
      "Validation Report saved successfully, explore a summary at https://c.app.hopsworks.ai:443/p/1279136/fs/1265746/fg/1718851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Uploading Dataframe: 100.00% |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| Rows 11/11 | Elapsed Time: 00:00 | Remaining Time: 00:00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Launching job: weather_extended_1_offline_fg_materialization\n",
      "Job started successfully, you can follow the progress at \n",
      "https://c.app.hopsworks.ai:443/p/1279136/jobs/named/weather_extended_1_offline_fg_materialization/executions\n",
      "2025-11-17 21:52:55,775 INFO: Waiting for execution to finish. Current state: SUBMITTED. Final status: UNDEFINED\n",
      "2025-11-17 21:52:58,949 INFO: Waiting for execution to finish. Current state: RUNNING. Final status: UNDEFINED\n",
      "2025-11-17 21:54:40,643 INFO: Waiting for execution to finish. Current state: AGGREGATING_LOGS. Final status: SUCCEEDED\n",
      "2025-11-17 21:54:40,804 INFO: Waiting for log aggregation to finish.\n",
      "2025-11-17 21:55:03,121 INFO: Execution finished successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Job('weather_extended_1_offline_fg_materialization', 'SPARK'),\n",
       " {\n",
       "   \"success\": true,\n",
       "   \"results\": [\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"wind_speed_10m_max\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 1000.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 758980\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 6.369049549102783,\n",
       "         \"element_count\": 11,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2025-11-17T08:52:38.000678Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     },\n",
       "     {\n",
       "       \"success\": true,\n",
       "       \"expectation_config\": {\n",
       "         \"expectation_type\": \"expect_column_min_to_be_between\",\n",
       "         \"kwargs\": {\n",
       "           \"column\": \"precipitation_sum\",\n",
       "           \"min_value\": -0.1,\n",
       "           \"max_value\": 1000.0,\n",
       "           \"strict_min\": true\n",
       "         },\n",
       "         \"meta\": {\n",
       "           \"expectationId\": 758981\n",
       "         }\n",
       "       },\n",
       "       \"result\": {\n",
       "         \"observed_value\": 0.0,\n",
       "         \"element_count\": 11,\n",
       "         \"missing_count\": null,\n",
       "         \"missing_percent\": null\n",
       "       },\n",
       "       \"meta\": {\n",
       "         \"ingestionResult\": \"INGESTED\",\n",
       "         \"validationTime\": \"2025-11-17T08:52:38.000678Z\"\n",
       "       },\n",
       "       \"exception_info\": {\n",
       "         \"raised_exception\": false,\n",
       "         \"exception_message\": null,\n",
       "         \"exception_traceback\": null\n",
       "       }\n",
       "     }\n",
       "   ],\n",
       "   \"evaluation_parameters\": {},\n",
       "   \"statistics\": {\n",
       "     \"evaluated_expectations\": 2,\n",
       "     \"successful_expectations\": 2,\n",
       "     \"unsuccessful_expectations\": 0,\n",
       "     \"success_percent\": 100.0\n",
       "   },\n",
       "   \"meta\": {\n",
       "     \"great_expectations_version\": \"0.18.12\",\n",
       "     \"expectation_suite_name\": \"weather_expectation_suite\",\n",
       "     \"run_id\": {\n",
       "       \"run_name\": null,\n",
       "       \"run_time\": \"2025-11-17T21:52:38.678166+01:00\"\n",
       "     },\n",
       "     \"batch_kwargs\": {\n",
       "       \"ge_batch_id\": \"5a3d01b4-c3f7-11f0-8867-43d604ba8dc7\"\n",
       "     },\n",
       "     \"batch_markers\": {},\n",
       "     \"batch_parameters\": {},\n",
       "     \"validation_time\": \"20251117T205238.678015Z\",\n",
       "     \"expectation_suite_meta\": {\n",
       "       \"great_expectations_version\": \"0.18.12\"\n",
       "     }\n",
       "   }\n",
       " })"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert new data\n",
    "weather_fg.insert(daily_df, wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83e9e2d",
   "metadata": {},
   "source": [
    "## <span style=\"color:#ff5f27;\">‚è≠Ô∏è **Next:** Part 03: Training Pipeline\n",
    " </span> \n",
    "\n",
    "In the following notebook you will read from a feature group and create training dataset within the feature store\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
